{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기술스택 선택을 위한 skill.json파일 생성하기\n",
    "- 각 사이트의 ```\"기술스택\"``` column을 받아와서 단어별로 쪼갬\n",
    "- **{\"기술스택\": \"소문자 기술스택\"}** 형태의 json 파일 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.read_csv('../Data_Pretreatment/Data_result/pre_result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "wanted = pd.read_csv('../Data_Pretreatment/Data_result/pre_wanted.csv')['기술 스택']\n",
    "jobplanet = pd.read_csv('../Data_Pretreatment/Data_result/pre_jobplanet.csv')['기술 스택']\n",
    "jumpit = pd.read_csv('../Data_Pretreatment/Data_result/pre_jumpit.csv')['기술 스택']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#기술스택에 있는 내용 단어별로 쪼개기\n",
    "def word_split(site_name):\n",
    "    result_set = set()\n",
    "    for i in site_name.unique():\n",
    "        if type(i) == float:\n",
    "            continue\n",
    "        result_set = result_set.union(set(i.split()))\n",
    "        \n",
    "    return result_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_set = word_split(jobplanet).union(word_split(wanted),word_split(jumpit))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 중복 처리한 기술스택 중 1차 가공(한글만 들어있는 것) 후 ```skill.json```파일로 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result_set' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m words \u001b[39m=\u001b[39m {}\n\u001b[1;32m----> 3\u001b[0m \u001b[39mfor\u001b[39;00m word \u001b[39min\u001b[39;00m result_set:\n\u001b[0;32m      4\u001b[0m     \u001b[39mif\u001b[39;00m re\u001b[39m.\u001b[39mmatch(\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39m[ㄱ-ㅎ가-힣]+\u001b[39m\u001b[39m'\u001b[39m, word) \u001b[39m==\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m      5\u001b[0m         word \u001b[39m=\u001b[39m word\u001b[39m.\u001b[39mreplace(\u001b[39m'\u001b[39m\u001b[39m,\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'result_set' is not defined"
     ]
    }
   ],
   "source": [
    "words = {}\n",
    "\n",
    "for word in result_set:\n",
    "    if re.match(r'[ㄱ-ㅎ가-힣]+', word) == None:\n",
    "        word = word.replace(',','')\n",
    "        words[word] = word.lower()\n",
    "\n",
    "print(words)\n",
    "with open('skill.json', 'w', encoding=\"utf-8\") as json_file:\n",
    "    json.dump(words, json_file, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 추천 ui 부분 그래프 및 직무 결과 도출 함수\n",
    "- input: 추천 결과 공고?\n",
    "- 직무내용 count, 기술스택 count -> json형태"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result로 특정 개수의 결과가 전달 되었다고 가정\n",
    "#result = pd.read_csv('../Data_Pretreatment/Data_result/pre_result.csv')\n",
    "with open('recommends_data.json', 'r', encoding=\"utf-8\") as json_file:\n",
    "        data = json.load(json_file)\n",
    "\n",
    "result = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "#type은 추천 공고의 output을 보고 결정\n",
    "\n",
    "def graph_job_view(result):\n",
    "    job_count_df = pd.DataFrame(result)\n",
    "\n",
    "    #데이터 df화 시킨 후 '직무내용'열에서 가장 빈도수가 높은 단어 추출\n",
    "    job_count_df['직무내용'] = job_count_df['직무내용'].str.split(', ')\n",
    "    word_frequency = job_count_df['직무내용'].explode().value_counts()\n",
    "    max_frequency = word_frequency.max()\n",
    "    most_common_words = ', '.join(word_frequency[word_frequency == max_frequency].index)\n",
    "\n",
    "\n",
    "    # 기존 Counter를 사용한 코드\n",
    "    # for data in result:\n",
    "    #     print(data['직무내용'])\n",
    "    #     job_count += Counter(data['직무내용'].split(','))\n",
    "\n",
    "    # job_count.most_common()\n",
    "    # highest_keys = [item[0] for item in most_common_items if item[1] == most_common_items[0][1]]\n",
    "\n",
    "    # return json.dumps(dict(job_count), ensure_ascii=False)\n",
    "    return most_common_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'QA 엔지니어'"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_job_view(result)\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_skill_view(result):\n",
    "    with open('tech_stack.json', 'r', encoding=\"utf-8\") as json_file:\n",
    "        data = json.load(json_file)\n",
    "\n",
    "    # def teck_stack_search(data):\n",
    "    #     for key, value in data.items():\n",
    "    #         if isinstance(value, list):\n",
    "\n",
    "    #         else:\n",
    "\n",
    "        tech_li = []\n",
    "        for words in result['자격요건'] + result['주요업무']:\n",
    "            for key, value in data.items():\n",
    "                if isinstance(value, list):\n",
    "                    for tech in value:\n",
    "                        if tech in words.lower():\n",
    "                            tech_li.append(key)\n",
    "                            continue\n",
    "\n",
    "                elif value in words.lower():\n",
    "                    tech_li.append(key)\n",
    "    print(tech_li)\n",
    "    return dict(Counter(tech_li).most_common())\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "['RabbitMQ', 'Docker', 'MQ', 'CTI', 'Device', 'Linux', 'Go언어', 'Git', 'framework', 'Postgres', 'Redis', 'PostgreSQL', 'FastAPI', 'Python', 'Jira', 'CTI', 'Figma', 'Material', 'Next.js', 'Studio', 'TypeScript', 'Git', 'Jest', 'Material-UI', 'Cypress', 'Linux', 'AWS', 'Python', 'RabbitMQ', 'Spring', 'Docker', 'MQ', 'Linux', 'AWS', 'Redis', 'Kotlin', 'Postman', 'FastAPI', 'Python', 'Gradle', 'Linux', 'AWS', 'Postman', 'Python', 'Linux', 'Postman', 'Python', 'MySQL', 'Linux', 'Java', 'Express.js', 'Git', 'SQL', 'CentOS', 'Javascript', 'Node.js', 'Node.js', 'Ubuntu', 'Mybatis', 'REST', 'RabbitMQ', 'Spring', 'Docker', 'MQ', 'AWS', 'Redis', 'Kotlin', 'FastAPI', 'Python', 'Gradle', 'RabbitMQ', 'Spring', 'Docker', 'MQ', 'Linux', 'AWS', 'Redis', 'Kotlin', 'FastAPI', 'Python', 'Gradle', 'Linux', 'Python', 'Figma', 'B2B', 'Axure', 'C++', 'OpenCV', 'C#', 'PLC', 'C++', 'MFC', 'embedded', 'RabbitMQ', 'Docker', 'MQ', 'CTI', 'Device', 'Go언어', 'Git', 'framework', 'Postgres', 'Redis', 'PostgreSQL', 'FastAPI', 'Python', 'DevOps', 'ETL', 'Git', 'MSSQL', 'SQL', 'SQL', 'Azure', 'Project', 'SSIS', 'server', 'UART', 'Kubernetes', 'CTI', 'DevOps', 'ERP', 'ISE', 'Git', 'MSSQL', 'Azure', 'Prometheus', 'Argo', 'POWER', 'Java', 'Javascript', 'Node.js', 'PyTorch', 'DevOps', 'ETL', 'Git', 'MSSQL', 'SQL', 'SQL', 'Azure', 'Project', 'SSIS', 'server', 'UART']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Python': 9,\n",
       " 'Linux': 8,\n",
       " 'Git': 7,\n",
       " 'RabbitMQ': 5,\n",
       " 'Docker': 5,\n",
       " 'MQ': 5,\n",
       " 'Redis': 5,\n",
       " 'FastAPI': 5,\n",
       " 'AWS': 5,\n",
       " 'SQL': 5,\n",
       " 'CTI': 4,\n",
       " 'Spring': 3,\n",
       " 'Kotlin': 3,\n",
       " 'Postman': 3,\n",
       " 'Gradle': 3,\n",
       " 'Node.js': 3,\n",
       " 'DevOps': 3,\n",
       " 'MSSQL': 3,\n",
       " 'Azure': 3,\n",
       " 'Device': 2,\n",
       " 'Go언어': 2,\n",
       " 'framework': 2,\n",
       " 'Postgres': 2,\n",
       " 'PostgreSQL': 2,\n",
       " 'Figma': 2,\n",
       " 'Java': 2,\n",
       " 'Javascript': 2,\n",
       " 'C++': 2,\n",
       " 'ETL': 2,\n",
       " 'Project': 2,\n",
       " 'SSIS': 2,\n",
       " 'server': 2,\n",
       " 'UART': 2,\n",
       " 'Jira': 1,\n",
       " 'Material': 1,\n",
       " 'Next.js': 1,\n",
       " 'Studio': 1,\n",
       " 'TypeScript': 1,\n",
       " 'Jest': 1,\n",
       " 'Material-UI': 1,\n",
       " 'Cypress': 1,\n",
       " 'MySQL': 1,\n",
       " 'Express.js': 1,\n",
       " 'CentOS': 1,\n",
       " 'Ubuntu': 1,\n",
       " 'Mybatis': 1,\n",
       " 'REST': 1,\n",
       " 'B2B': 1,\n",
       " 'Axure': 1,\n",
       " 'OpenCV': 1,\n",
       " 'C#': 1,\n",
       " 'PLC': 1,\n",
       " 'MFC': 1,\n",
       " 'embedded': 1,\n",
       " 'Kubernetes': 1,\n",
       " 'ERP': 1,\n",
       " 'ISE': 1,\n",
       " 'Prometheus': 1,\n",
       " 'Argo': 1,\n",
       " 'POWER': 1,\n",
       " 'PyTorch': 1}"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re = pd.DataFrame(result)\n",
    "print(len(re))\n",
    "graph_skill_view(re)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crawl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
