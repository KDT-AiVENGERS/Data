# -*- coding: utf-8 -*-
"""
2023.07.17 Mon
ìœ ë°ë¯¸ ì‚¬ì´íŠ¸ì˜ ê°•ì˜(í‰ì  4.5 ì´ìƒì¸ ê°•ì˜ë§Œ) ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ëŠ” ì½”ë“œì…ë‹ˆë‹¤. 9ë²ˆ, 10ë²ˆ, 13ë²ˆ ë¼ì¸ë§Œ í™•ì¸ ë° ë³€ê²½í•´ì£¼ì‹œë©´ ë©ë‹ˆë‹¤!
ì½”ë“œ ì‹¤í–‰ ì¤‘ ì—ëŸ¬ ë°œìƒìœ¼ë¡œ ì¤‘ë‹¨ë  ê²½ìš°, current_info.pickle íŒŒì¼ë¡œ í˜„ì¬ ì •ë³´ê°€ ì €ì¥ë©ë‹ˆë‹¤.
"""
# ğŸŒŸ ê°ì ìˆ˜ì§‘í•˜ê¸°ë¡œ í•œ ì¹´í…Œê³ ë¦¬ index numberì˜ ì‹œì‘ ìˆ«ì, ë ìˆ«ìë¥¼ í•˜ë‚˜ì”© ì…ë ¥í•´ì£¼ì„¸ìš”! (ìŠ¹ë¦¼ : 1,2,3)(ì¬í˜„ : 4,5,6)(ì¸í˜¸ : 7,8,9)
# 7,8,9ë²ˆì„ ë‹´ë‹¹í–ˆë‹¤ë©´ start_idx = 7, end_idx = 9 ì…ë‹ˆë‹¤.
start_idx = 1 
end_idx = 3

# ğŸŒŸ ì¤‘ê°„ì— ì½”ë“œê°€ ëŠê²¨ì„œ ë‹¤ì‹œ ì¬ì‹œì‘í•˜ë‚˜ìš”? ê·¸ëŸ¬ë©´ restart = True ë¡œ ë³€ê²½í•´ì£¼ì„¸ìš”. ë³€ê²½í•˜ì§€ ì•Šìœ¼ë©´ ì²˜ìŒë¶€í„° ë‹¤ì‹œ ìˆ˜ì§‘ë˜ë‹ˆ ì£¼ì˜í•´ì£¼ì„¸ìš”!
restart = False

# 1. í•„ìš” ëª¨ë“ˆ ê°€ì ¸ì˜¤ê¸°
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import undetected_chromedriver as uc
import datetime
import time
import pandas as pd
import numpy as np
import pickle as pkl
from tqdm import tqdm

# 2. ì‹¤í–‰ì‹œê°„ ì¸¡ì •
start_time = time.time()

# 3. ë°ì´í„°í”„ë ˆì„ ë° ì¹´í…Œê³ ë¦¬ ì •ì˜
df = pd.DataFrame(columns=['ëŒ€ë¶„ë¥˜', 'ì†Œë¶„ë¥˜', 'ê°•ì˜ëª…', 'ë‚œì´ë„', 'ê°€ê²©(í˜„ì¬ê°€ê²©)','ê°€ê²©(ì›ë˜ê°€ê²©)', 'ì´ì†Œìš”ì‹œê°„', 'ê°•ì˜ì†Œê°œ', 'ì–¸ì–´', 'ì¶œì²˜']) 

categories = ["web-development", "data-science", "mobile-apps", "programming-languages", "game-development",
              "databases", "software-testing", "software-engineering", "development-tools", "no-code-development"]

# 4. current_infoë¥¼ ì €ì¥í•  pkl íŒŒì¼ ì •ë³´ ìƒì„±
current_info = {"category": categories[start_idx], "page": 1, "last_page": "(í™•ì¸ì˜ˆì •)", "lec_num": 0}
lec_count = current_info['lec_num']

# 5. ì—ëŸ¬ ë•Œë¬¸ì— ì¤‘ê°„ë¶€í„° ë‹¤ì‹œ ì‹œì‘í•˜ëŠ” ìƒí™© ëŒ€ë¹„
if restart == True:
    df = pd.read_csv(f"./udemy_{current_info['category']}_230718.csv") 
    with open('current_info.pickle', 'rb') as file:
        current_info = pkl.load(file)

    start_idx = categories.index(current_info['category'])
    if current_info['lec_num']==15: #ê°•ì˜ê°€ 16ê°œ(idx 0~15)ì´ë¯€ë¡œ ë§ˆì§€ë§‰ ê°•ì˜ë©´ ë‹¤ìŒ í˜ì´ì§€ë¡œ ë„˜ì–´ê°‘ë‹ˆë‹¤.
        current_info['page']+= 1
        current_info['lec_num'] = 0
    lec_count = current_info['lec_num'] + 1

# 6. ë¶ˆëŸ¬ì˜¨ ë³€ìˆ˜ í™•ì¸ í›„ í¬ë¡¤ë§ ì‹œì‘!
print(f"í¬ë¡¤ë§ ì‹œì‘ : ğŸ‘ {current_info['category']} : ì´ {current_info['last_page']}í˜ì´ì§€ ì¤‘ {current_info['page']}ë²ˆì§¸ í˜ì´ì§€ì˜ {current_info['lec_num']}ë²ˆì§¸ ê°•ì˜ë¶€í„° ìˆ˜ì§‘ ì‹œì‘ ")

# 7. ì¹´í…Œê³ ë¦¬(ëŒ€ë¶„ë¥˜) ëŒê¸°
try:
    for category in categories[start_idx:(end_idx + 1)]:
        options = uc.ChromeOptions()
        driver = uc.Chrome(use_subprocess=True, options=options)
        last_page = current_info['last_page']
        if last_page == "(í™•ì¸ì˜ˆì •)":
            while True:
                try:     
                    driver.get(f"https://www.udemy.com/ko/courses/development/{category}/?p=1&ratings=4.5&sort=popularity")
                    break
                except Exception as e:
                    exception_name = type(e).__name__
                    print(f"ğŸ¥² ë„¤íŠ¸ì›Œí¬ê°€ ì—°ê²°ì´ ì˜ ì•ˆë¼ìš”... Exception: {exception_name}")
                    time.sleep(3)
            driver.maximize_window()
            time.sleep(5)
            last_page = int(driver.find_element(By.XPATH, '//*[@aria-label="ìƒëµ ë¶€í˜¸"]/following-sibling::span').text) #ë§ˆì§€ë§‰ í˜ì´ì§€ ë²ˆí˜¸
            current_info['last_page'] = last_page
        current_info['category'] = category
        with open('current_info.pickle', 'wb') as file: # pickle íŒŒì¼ë¡œ ì €ì¥
            pkl.dump(current_info, file)

        # 8. 1í˜ì´ì§€ë¶€í„° last_pageê¹Œì§€ í˜ì´ì§€ë³„ ê°•ì˜(lec) í¬ë¡¤ë§
        for page in tqdm(range(current_info['page'], last_page + 1)):
            current_info["page"] = page
            while True:
                try:     
                    driver.get(f"https://www.udemy.com/ko/courses/development/{category}/?p={page}&ratings=4.5&sort=popularity")
                    break
                except Exception as e:
                    exception_name = type(e).__name__
                    print(f"ğŸ¥² ë„¤íŠ¸ì›Œí¬ê°€ ì—°ê²°ì´ ì˜ ì•ˆë¼ìš”... Exception: {exception_name}")
                    time.sleep(3)
            with open('current_info.pickle', 'wb') as file:  # pickle íŒŒì¼ë¡œ ì €ì¥
                pkl.dump(current_info, file)
            time.sleep(3)
            lec_container = driver.find_element(By.XPATH, '//div[@class="filter-panel--paginated-course-list--A07TT"]')
            lec_boxes = lec_container.find_elements(By.XPATH, '//div[@class="course-card--main-content--2XqiY course-card--has-price-text--1c0ze"]')

            # íƒœê·¸ê°€ ì—†ëŠ” ê²½ìš°, nanê°’ì„ í• ë‹¹í•˜ê³  ë„˜ì–´ê°€ëŠ” í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
            def find_element_nan(driver, path):
                try:
                    element = driver.find_element(By.XPATH, path)
                    return element.text
                except:
                    return np.nan
                
            # 9. í˜ì´ì§€ë³„ ê°•ì˜ ìƒì„¸ë‚´ìš© í¬ë¡¤ë§ ì‹œì‘    
            url_list = [] #í˜ì´ì§€ë§ˆë‹¤ ë¦¬ì…‹
            for box in lec_boxes:
                a_tag = box.find_element(By.TAG_NAME, 'a')
                urls = a_tag.get_attribute('href')
                lec_times = find_element_nan(box, '//div[@data-purpose="course-meta-info"]/span[1]')
                levels = find_element_nan(box, '//div[@data-purpose="course-meta-info"]/span[3]')
                now_prices = find_element_nan(box, '//div[@data-purpose="course-price-text"]/span[2]')
                raw_prices = find_element_nan(box, '//div[@data-purpose="course-old-price-text"]/span[2]')
                url_list.append((urls, lec_times, levels, now_prices, raw_prices))

            for url_idx, (urls, lec_times, levels, now_prices, raw_prices) in enumerate(url_list):
                if url_idx >= lec_count:
                    while True:
                        try:     
                            driver.get(urls)
                            time.sleep(3)
                            break
                        except Exception as e:
                            exception_name = type(e).__name__
                            print(f"ğŸ¥² ë„¤íŠ¸ì›Œí¬ê°€ ì—°ê²°ì´ ì˜ ì•ˆë¼ìš”... Exception: {exception_name}")
                            time.sleep(3)
                    current_info["lec_num"] = url_idx
                    with open('current_info.pickle', 'wb') as file: # pickle íŒŒì¼ë¡œ ì €ì¥
                        pkl.dump(current_info, file)
                    driver.maximize_window()
                    time.sleep(3)
                    
                    try:
                        hashtags_parent = driver.find_element(By.CLASS_NAME, 'topic-menu.topic-menu-condensed.ud-breadcrumb')
                        hashtags_a = hashtags_parent.find_elements(By.TAG_NAME, 'a')
                        hashtag = hashtags_a[-1].text
                    except:
                        hashtag = np.nan

                    title = find_element_nan(driver, '//h1[@data-purpose="lead-title"]')
                    level = levels
                    now_price = now_prices
                    raw_price = raw_prices
                    lec_time = lec_times
                    body = find_element_nan(driver, '//div[@class="component-margin what-you-will-learn--what-will-you-learn--1nBIT"]')
                    language = find_element_nan(driver, '//div[@data-purpose="lead-course-locale"]')
                    url = urls

                    # 8. csv í˜•íƒœë¡œ ì¶”ì¶œ
                    new_row = {'ëŒ€ë¶„ë¥˜': category, 'ì†Œë¶„ë¥˜': hashtag, 'ê°•ì˜ëª…': title, 'ë‚œì´ë„': level, 
                            'ê°€ê²©(í˜„ì¬ê°€ê²©)': now_price, 'ê°€ê²©(ì›ë˜ê°€ê²©)': raw_price, 'ì´ì†Œìš”ì‹œê°„': lec_time, 
                            'ê°•ì˜ì†Œê°œ': body, 'ì–¸ì–´': language, 'ì¶œì²˜': url}
                    df = pd.concat([df, pd.DataFrame(new_row, index=[0])], ignore_index=True)
                    df.to_csv(f'./udemy_{category}_230718.csv', index=False)
            lec_count = 0
        driver.quit()

except KeyboardInterrupt:
    print(f"ğŸ‘ {current_info['category']} : ì´ {current_info['last_page']}í˜ì´ì§€ ì¤‘ {current_info['page']}ë²ˆì§¸ í˜ì´ì§€ì˜ {current_info['lec_num']}ë²ˆì§¸ ê°•ì˜ê¹Œì§€ ìˆ˜ì§‘ ì™„ë£Œ ")


# 10. ì´ ì‹¤í–‰ ì‹œê°„ ì¶œë ¥
print(len(df), 'ê°œ ë°ì´í„° í¬ë¡¤ë§ ì™„ë£Œ')
end_time = time.time()
execution_time = end_time - start_time

hours = int(execution_time // 3600)
minutes = int((execution_time % 3600) // 60)
seconds = int(execution_time % 60)
print("ì‘ì—… ì‹¤í–‰ ì‹œê°„: {}ì‹œê°„ {}ë¶„ {}ì´ˆ".format(hours, minutes, seconds))